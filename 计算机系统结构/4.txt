19.  请简述向量体系结构和GPU体系结构的差异。
		○ 向量体系结构，指令流水线深，ALU宽度窄，单次指令流水后能处理更多数据，节省了不必要的流水时间。
		○ GPU，指令流水线浅，ALU宽度宽，流水本身比较简单，但能直接对更多的数据进行同时计算。
20.  请简述GPU和CPU在设计理念上的差异性。
		○ CPU：多核，核心少。运算单元少，控制单元多。每个核有独立的cache和控制单元。流水线。快速的指令级并行，快速的Cache访问，具有较少的Cache访问延迟；
		○ GPU：众核，核心多。运算单元多，控制单元少。多个核共享cache和控制单元。并发执行。强大的运算能力，强在并行的计算。 GPU距离内存较远，因此访存延迟较高，但是访问带宽较高，所以又称为“高通量计算”。
21.  请简述GPU各个层次组件间的相似性。
		○ 在任务的划分上，存在着自相似性，也就是每一个第i级的任务，都可以划分为一组i+1级的任务，并且同一级别的任务之间是并行的。
		○ 在硬件上，同样也体现出了自相似性。逐层的，都是相似的结构，包括调度器、任务的buffer、数据存储和处理单元。
		○ 每层组件中都包含 任务单元，调度单元，存储单元，计算单元，互联网络或总线。
22.  请简述GPGPU虚拟化的思想。
		○ 把一个GPU的计算能力分成多个切片，每个切片虚拟成一个GPU，将整个GPU的计算能力分给不同用户共享
		○ 一个GPU的SM很多，但是对于单用户只能用很少的SM,这样利用率很低；
		○ 硬件上把多个SM进行分割成多个切片，软件上为每个用户分配一个SM切片；
		○ 使得每个用户都能满负荷使用SM，每个用户感觉自己拥有了一个GPU
23.  请简述向量长度寄存器和向量屏蔽寄存器的作用。
		○ 向量长度寄存器VL：表示向量长度（≤64），控制所有有关向量长度的运算，将软件层程序中实际向量长度N与硬件层向量寄存器中的元素数目相匹配。
		○ 向量屏蔽寄存器VM：当向量实际长度＜64时，或对某些元素需要进行单独运算时使用。
24.  请简述循环间相关、可向量化、指令编队的思想。
		○ 循环间相关：对一个循环，若各轮迭代之间存在相关性，则称为循环间相关。
		○ 可向量化：针对一组MIPS指令描述的循环，若满足循环间无关，则称可向量化。编译器可以为其生成向量指令。
		○ 指令编队（convoy）：一组能够在同一时钟周期内一起开始执行的向量指令的集合组成。不存在结构冲突，不存在数据冲突或存在数据冲突但可以链接。一个编队中的所有向量指令在硬件条件允许时可以并行。
25.  请简述多车道技术、链接技术、分段开采技术的思想。
		○ 多车道技术：增加ALU单元，从而提升向量的计算速度。（增加吞吐量）
		○ 链接技术：若有两条指令出现“写后读”，如果不存在功能部件冲突（结构冲突）和寄存器冲突（源或目的相同），就可以把它们所用的的功能部件相链接，形成长流水线。
			§ 后面的功能只需等待前面第一个功能的第一个结果产生就可以开始进行
			§ 实际上就是向量体系中的定向技术
			§ “向量体系结构”页上的图片
			§ 保证无结构冲突和寄存器冲突
			§ 在前一条指令的第一个结果送入链接到的寄存器的时候开始
			§ 如果两个操作数都是链接而来，需要保证链接到达是同时的
			§ 保证链接执行的向量长度相等
		○ 分段开采技术：当循环的长度大于向量寄存器的长度，必须把向量分成长度较短的段，循环分多次处理。
			§ 由硬件和编译软件控制，对程序员透明
26.  影响向量体系结构性能的因素。
		○ 操作数向量的长度
		○ 向量启动时间
		○ 数据相关，是否使用链接技术
		○ 结构相关，发射限制，车道技术，编队
34. GPU和GPGPU的区别
		○ GPU，Graphics Processing Unit，图形处理器
			§ 极高的计算吞吐率，内存带宽
			§ 专用图形处理器
			§ 适合纹理图像等处理
		○ GPGPU，General-Purpose computing on GPUs，通用图形处理器
			§ 可以进行通用计算编程
			§ 适合处理SIMD
35.SPMD编程模型
		○ Single Program Multiple Data，单程序多数据
		○ 用多线程模型，而非向量指令
36.GPU编程模型
		○ CUDA=Compute Unified Device Architecture，统一计算设备框架
		○ CUDA用C++作为高级编程语言，采用SPMD编程方式
37.异构编程
		○ 主机采用CPU，运行C++程序；物理上分离的协处理器GPU，运行kernel程序，运行thread，运行CUDA目标代码。
38.辨析SPMD，SIMT，SIMD
	SPMD：GPU的编程模型
	SIMT：GPU的执行方式
	SIMD：GPU计算单元的处理方式
39.GPU如何处理分支分歧？（Branch Divergence）
		○ 同一warp中的不同thread在遇到分支指令时可能会有分歧，需要执行不同的路径。
		○ 但thread无法单独控制和调度，且并行的处理单元同一时钟只能处理相同操作
	每个WRAP用一个栈来处理分支分歧，记录warp中的有效thread
